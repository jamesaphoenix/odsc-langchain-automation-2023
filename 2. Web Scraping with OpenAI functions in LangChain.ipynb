{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9vHqEsY4qPq",
        "outputId": "3c924cde-3403-40ee-b62d-2daefa191e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (0.28.1)\n",
            "Requirement already satisfied: langchain in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (0.0.327)\n",
            "Requirement already satisfied: playwright in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (1.37.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (4.11.1)\n",
            "Requirement already satisfied: nest_asyncio in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (1.5.5)\n",
            "Requirement already satisfied: tiktoken in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (0.5.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement quiet (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for quiet\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai langchain playwright beautifulsoup4 nest_asyncio tiktoken -- quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CTaP1RKC4yud"
      },
      "outputs": [],
      "source": [
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lS9sNsUj5Pxr"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nwv68-CM5CZm"
      },
      "outputs": [],
      "source": [
        "# Insert your OpenAI API key here:\n",
        "\n",
        "# import os\n",
        "# os.environ['OPENAI_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w5ZWxdKw45nZ"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hDiJ1oGH4sl-"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"news_article_title\": {\"type\": \"string\"},\n",
        "        \"news_article_summary\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"news_article_title\", \"news_article_summary\"],\n",
        "}\n",
        "\n",
        "def extract(content: str, schema: dict):\n",
        "    return create_extraction_chain(schema=schema, llm=llm).run(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unT1F0bL48A8",
        "outputId": "52defe4d-2e4b-4db1-cd66-cb9875f5b5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting content with LLM\n",
            "[{'news_article_summary': 'Projects Services Posts Contact data engineering',\n",
            "  'news_article_title': 'About'},\n",
            " {'news_article_summary': 'React Development Python Programming Development '\n",
            "                          'Prompt Engineering Web Scraping SaaS Applications',\n",
            "  'news_article_title': 'Data Engineering'},\n",
            " {'news_article_summary': '',\n",
            "  'news_article_title': 'Soft Skills for Programmers: Why They Matter and How '\n",
            "                        'to Develop Them'},\n",
            " {'news_article_summary': '',\n",
            "  'news_article_title': 'What Are Webhooks? And How Do They Relate to Data '\n",
            "                        'Engineering?'},\n",
            " {'news_article_summary': '',\n",
            "  'news_article_title': 'What is an API? And How Do They Relate to Data '\n",
            "                        'Engineering?'}]\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import AsyncChromiumLoader\n",
        "from langchain.document_transformers import BeautifulSoupTransformer\n",
        "\n",
        "\n",
        "def scrape_with_playwright(urls, schema):\n",
        "    loader = AsyncChromiumLoader(urls)\n",
        "    docs = loader.load()\n",
        "    bs_transformer = BeautifulSoupTransformer()\n",
        "    docs_transformed = bs_transformer.transform_documents(docs,tags_to_extract=[\"a\"])\n",
        "    print(\"Extracting content with LLM\")\n",
        "\n",
        "    # Grab the first 1000 tokens of the site\n",
        "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000,\n",
        "                                                                    chunk_overlap=0)\n",
        "    splits = splitter.split_documents(docs_transformed)\n",
        "\n",
        "    # Process the first split\n",
        "    extracted_content = extract(\n",
        "        schema=schema, content=splits[0].page_content\n",
        "    )\n",
        "    pprint.pprint(extracted_content)\n",
        "    return extracted_content\n",
        "\n",
        "urls = ['https://understandingdata.com/']\n",
        "extracted_content = scrape_with_playwright(urls, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted content: [{'news_article_title': 'About', 'news_article_summary': 'Projects Services Posts Contact data engineering'}, {'news_article_title': 'Data Engineering', 'news_article_summary': 'React Development Python Programming Development Prompt Engineering Web Scraping SaaS Applications'}, {'news_article_title': 'Soft Skills for Programmers: Why They Matter and How to Develop Them', 'news_article_summary': ''}, {'news_article_title': 'What Are Webhooks? And How Do They Relate to Data Engineering?', 'news_article_summary': ''}, {'news_article_title': 'What is an API? And How Do They Relate to Data Engineering?', 'news_article_summary': ''}]\n"
          ]
        }
      ],
      "source": [
        "print(\"Extracted content:\", extracted_content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
